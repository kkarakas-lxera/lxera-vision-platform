#!/usr/bin/env python3
"""
LXERA Database Pipeline Integration
Modified to retrieve employee data and skills gaps from Supabase database
"""

import json
import logging
import asyncio
from datetime import datetime
from typing import Dict, Any, List, Optional
import uuid
import os
from supabase import create_client, Client

# Configure logger first before any usage
logger = logging.getLogger(__name__)

# Import the new SDK-based coordinator for comprehensive agent-based generation
from lxera_agents import Runner, trace
from course_agents.coordinator import create_course_generation_coordinator

class LXERADatabasePipeline:
    """
    SDK-based pipeline orchestrator that integrates with LXERA's Supabase database
    to retrieve employee data and skills gap analysis using OpenAI Agents SDK.
    """
    
    def __init__(self):
        
        # Initialize Supabase client with LXERA credentials
        # Use environment variables with hardcoded fallbacks for Render deployment
        self.supabase_url = os.getenv('SUPABASE_URL', 'https://xwfweumeryrgbguwrocr.supabase.co')
        self.supabase_key = os.getenv('SUPABASE_SERVICE_ROLE_KEY', 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Inh3ZndldW1lcnlyZ2JndXdyb2NyIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1MDc2MzQ0MCwiZXhwIjoyMDY2MzM5NDQwfQ.qxXpBxUKhKA4AQT4UQnIEJGbGNrRDMbBroZU8YaypSY') or os.getenv('SUPABASE_ANON_KEY')
            
        self.supabase: Client = create_client(self.supabase_url, self.supabase_key)
        logger.info("ðŸ”Œ Connected to LXERA Supabase database")
    
    async def generate_course_for_employee(
        self,
        employee_id: str,
        company_id: str,
        assigned_by_id: str,
        job_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Generate a personalized course for an employee using their existing skills gap analysis.
        
        Args:
            employee_id: Employee ID from database
            company_id: Company ID
            assigned_by_id: User ID who initiated the generation
            job_id: Optional job tracking ID
            
        Returns:
            Dict containing content_id and pipeline results
        """
        try:
            # Update job progress if tracking
            if job_id:
                await self._update_job_progress(job_id, {
                    'current_phase': 'Retrieving employee data',
                    'progress_percentage': 10
                })
            
            # Phase 1: Retrieve employee data from database
            employee_data = await self._retrieve_employee_data(employee_id)
            
            if job_id:
                await self._update_job_progress(job_id, {
                    'current_phase': 'Retrieving skills gap analysis',
                    'progress_percentage': 20,
                    'current_employee_name': employee_data.get('full_name', 'Unknown')
                })
            
            # Phase 2: Retrieve skills gap analysis
            skills_gaps = await self._retrieve_skills_gaps(employee_id, employee_data['position'])
            
            # Update job progress
            if job_id:
                await self._update_job_progress(job_id, {
                    'current_phase': 'Initializing AI agents',
                    'progress_percentage': 30
                })
            
            # Run the complete agentic pipeline with skills gaps using new SDK
            pipeline_result = await self._run_sdk_pipeline(
                employee_data,
                skills_gaps,
                job_id
            )
            
            # If successful, create course assignment
            if pipeline_result.get('pipeline_success') and pipeline_result.get('content_id'):
                assignment_id = await self._create_course_assignment(
                    employee_id,
                    pipeline_result['content_id'],
                    company_id,
                    assigned_by_id
                )
                pipeline_result['assignment_id'] = assignment_id
            
            # Final job update
            if job_id:
                await self._update_job_progress(job_id, {
                    'current_phase': 'Course generation complete',
                    'progress_percentage': 100,
                    'successful_courses': 1
                })
            
            return pipeline_result
            
        except Exception as e:
            logger.error(f"âŒ Course generation failed: {e}")
            if job_id:
                await self._update_job_progress(job_id, {
                    'status': 'failed',
                    'error_message': str(e)
                })
            raise
    
    async def _run_sdk_pipeline(
        self,
        employee_data: Dict[str, Any],
        skills_gaps: List[Dict[str, Any]],
        job_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Run the course generation pipeline using OpenAI SDK with automated agent handoffs.
        """
        try:
            logger.info("ðŸš€ Starting SDK-based course generation pipeline")
            
            # Update job progress
            if job_id:
                await self._update_job_progress(job_id, {
                    'current_phase': 'Running Planning Agent',
                    'progress_percentage': 40
                })
            
            # Phase 1: Planning Agent
            from course_agents.planning_agent import create_planning_agent
            planning_agent = create_planning_agent()
            
            planning_message = f"""
            Create a comprehensive personalized course plan for {employee_data['full_name']}.
            
            EMPLOYEE PROFILE:
            {json.dumps(employee_data, indent=2)}
            
            SKILLS GAP ANALYSIS:
            {json.dumps(skills_gaps, indent=2)}
            
            Execute the 6-step planning workflow:
            1. analyze_employee_profile
            2. prioritize_skill_gaps  
            3. generate_course_structure_plan
            4. generate_research_queries
            5. create_personalized_learning_path
            6. store_course_plan
            
            Complete these steps and store the final course plan.
            """
            
            # Update job progress for planning phase
            if job_id:
                await self._update_job_progress(job_id, {
                    'current_phase': 'Planning Phase: Creating personalized course structure',
                    'progress_percentage': 30
                })
            
            plan_id = None
            with trace("planning_phase"):
                planning_result = await Runner.run(
                    planning_agent,
                    planning_message,
                    max_turns=8  # Reduced limit - 6 steps + 2 for final response
                )
            
            # Extract plan_id from planning result
            plan_id = self._extract_plan_id(planning_result)
            
            if not plan_id:
                logger.error("âŒ Planning phase failed - no plan_id found")
                return {
                    'pipeline_success': False,
                    'error': 'Planning phase failed to produce a course plan',
                    'content_id': None
                }
            
            logger.info(f"âœ… Planning phase completed with plan_id: {plan_id}")
            
            # Phase 2: Research Agent
            if job_id:
                await self._update_job_progress(job_id, {
                    'current_phase': 'Research Phase: Gathering course content',
                    'progress_percentage': 60
                })
            
            from course_agents.research_agent import create_research_agent
            research_agent = create_research_agent()
            
            research_message = f"""
            Execute comprehensive research for course plan_id: {plan_id}
            
            Follow this exact workflow:
            1. fetch_course_plan - Load the course plan details using plan_id: {plan_id}
            2. tavily_search - Search for relevant content for each module topic
            3. firecrawl_extract - Extract detailed content from authoritative sources
            4. research_synthesizer - Synthesize findings into structured insights
            5. store_research_results - Save your research findings
            
            Focus on finding practical, industry-relevant content for the learner.
            """
            
            with trace("research_phase"):
                final_result = await Runner.run(
                    research_agent,
                    research_message,
                    max_turns=30  # Allow more turns for content generation
                )
            
            # Update job progress
            if job_id:
                await self._update_job_progress(job_id, {
                    'current_phase': 'Processing pipeline results',
                    'progress_percentage': 90
                })
            
            # Extract results from SDK pipeline run
            pipeline_success = True
            content_id = None
            
            # Try to extract content_id from final result
            final_output_text = ""
            if isinstance(final_result, dict):
                final_output_text = str(final_result.get('content', ''))
                pipeline_success = final_result.get('success', True)
            elif hasattr(final_result, 'final_output') and final_result.final_output:
                final_output_text = str(final_result.final_output)
            
            if final_output_text:
                # Look for content_id in the output
                import re
                content_id_match = re.search(r'content[_-]id[:\s]*([a-f0-9\-]{36})', final_output_text, re.IGNORECASE)
                if content_id_match:
                    content_id = content_id_match.group(1)
            
            # If no content_id found, generate a placeholder
            if not content_id:
                content_id = str(uuid.uuid4())
                logger.warning(f"âš ï¸ No content_id found in result, using placeholder: {content_id}")
            
            logger.info(f"âœ… SDK Pipeline completed with content_id: {content_id}")
            
            # Extract agent information
            if isinstance(final_result, dict):
                agent_name = final_result.get('agent_name', 'sdk_pipeline')
                total_turns = final_result.get('turns', 1)
                agent_result = final_result.get('content', str(final_result))
            else:
                agent_result = final_result.final_output if hasattr(final_result, 'final_output') else str(final_result)
                agent_name = final_result.last_agent if hasattr(final_result, 'last_agent') else 'sdk_pipeline'
                total_turns = len(final_result.raw_responses) if hasattr(final_result, 'raw_responses') else 1
            
            return {
                'pipeline_success': pipeline_success,
                'content_id': content_id,
                'agent_result': agent_result,
                'agent_name': agent_name,
                'turns': total_turns,
                'sdk_handoffs': True  # Indicate this used SDK handoffs
            }
            
        except Exception as e:
            logger.error(f"âŒ SDK Pipeline failed: {e}")
            return {
                'pipeline_success': False,
                'error': str(e),
                'content_id': None
            }
    
    def _extract_plan_id(self, result) -> str:
        """Extract plan_id from agent result."""
        try:
            # Log the result type for debugging
            logger.info(f"Extracting plan_id from result type: {type(result)}")
            
            # Get the output text
            output_text = ""
            
            # First check final_output
            if hasattr(result, 'final_output') and result.final_output:
                output_text = str(result.final_output)
                logger.info(f"Using final_output: {output_text[:200]}...")
            
            # Also check raw_responses for tool results
            if hasattr(result, 'raw_responses'):
                logger.info(f"Checking {len(result.raw_responses)} raw responses")
                for response in result.raw_responses:
                    if hasattr(response, 'content'):
                        for content_block in response.content:
                            if hasattr(content_block, 'type') and content_block.type == 'tool_result':
                                tool_result = str(content_block.content)
                                output_text += tool_result + " "
                                # Log if we find a plan_id in tool results
                                if "Course plan stored successfully with ID:" in tool_result:
                                    logger.info(f"Found plan_id in tool result: {tool_result[:100]}...")
            
            # If still no output_text, try dict format
            if not output_text and isinstance(result, dict):
                output_text = str(result.get('content', ''))
            
            # Look for plan_id pattern
            import re
            # More comprehensive pattern that matches the tool output format
            patterns = [
                r'Course plan stored successfully with ID:\s*([a-f0-9\-]{36})',
                r'(?:plan[_-]id|ID)[:\s]*([a-f0-9\-]{36})',
                r'([a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12})'  # Match any UUID
            ]
            
            for pattern in patterns:
                plan_id_match = re.search(pattern, output_text, re.IGNORECASE)
                if plan_id_match:
                    plan_id = plan_id_match.group(1)
                    logger.info(f"âœ… Found plan_id using pattern '{pattern}': {plan_id}")
                    return plan_id
            
            # Log the full output for debugging if no plan_id found
            logger.warning(f"âŒ No plan_id found in output. Full text: {output_text[:500]}...")
                
            return None
            
        except Exception as e:
            logger.error(f"Error extracting plan_id: {e}")
            return None
    
    def _check_planning_completion(self, planning_result) -> bool:
        """Check if Planning Agent completed successfully by looking for completion indicators."""
        try:
            # Handle dict format from lxera_agents.Runner.run()
            if isinstance(planning_result, dict):
                # Check success flag
                if planning_result.get('success'):
                    logger.info("âœ… Planning completion detected: success flag is True")
                    
                    # Check content for completion indicators
                    content = planning_result.get('content', '')
                    completion_indicators = [
                        'planning is complete',
                        'course plan has been successfully',
                        'planning complete',
                        'stored with the identifier',
                        'you can proceed with the next phase'
                    ]
                    
                    for indicator in completion_indicators:
                        if indicator in content.lower():
                            logger.info(f"âœ… Planning completion confirmed: '{indicator}' found in content")
                            return True
                    
                    # Even if no specific indicators, success=True is a good sign
                    return True
                else:
                    logger.warning("âš ï¸ Planning result indicates failure")
                    return False
            
            # Handle RunResult object format (fallback)
            if hasattr(planning_result, 'raw_responses'):
                store_course_plan_called = False
                completion_message_found = False
                
                for response in planning_result.raw_responses:
                    # Check for store_course_plan tool call
                    if hasattr(response, 'content') and response.content:
                        for content_block in response.content:
                            if hasattr(content_block, 'type') and content_block.type == 'tool_use':
                                if hasattr(content_block, 'name') and content_block.name == 'store_course_plan':
                                    store_course_plan_called = True
                                    logger.info("âœ… Planning completion detected: store_course_plan tool called")
                    
                    # Check for completion message in tool results
                    if hasattr(response, 'content') and response.content:
                        for content_block in response.content:
                            if hasattr(content_block, 'type') and content_block.type == 'tool_result':
                                if hasattr(content_block, 'content'):
                                    result_text = str(content_block.content).lower()
                                    if 'planning_complete_trigger_handoff' in result_text or 'course plan stored successfully' in result_text:
                                        completion_message_found = True
                                        logger.info("âœ… Planning completion detected: completion message found in tool results")
                
                if store_course_plan_called:
                    logger.info("âœ… Planning completion detected: store_course_plan tool called")
                    return True
            
            # Fallback: Check final output for completion indicators
            if hasattr(planning_result, 'final_output') and planning_result.final_output:
                output_text = str(planning_result.final_output).lower()
                
                completion_indicators = [
                    'planning_complete_trigger_handoff',
                    'course plan stored successfully',
                    'planning workflow completed',
                    'all 6 steps completed'
                ]
                
                for indicator in completion_indicators:
                    if indicator in output_text:
                        logger.info(f"âœ… Planning completion detected: '{indicator}' found in final output")
                        return True
            
            logger.warning("âš ï¸ No clear planning completion indicators found")
            return False
            
        except Exception as e:
            logger.error(f"Error checking planning completion: {e}")
            return False
    
    async def _retrieve_employee_data(self, employee_id: str) -> Dict[str, Any]:
        """Retrieve employee data from Supabase database."""
        try:
            # Get employee with user data
            response = self.supabase.table('employees').select(
                """
                id,
                position,
                department,
                career_goal,
                key_tools,
                company_id,
                users!inner (
                    full_name,
                    email
                )
                """
            ).eq('id', employee_id).single().execute()
            
            if not response.data:
                raise Exception(f"Employee {employee_id} not found")
            
            employee = response.data
            
            # Transform to expected format
            return {
                'id': employee['id'],
                'full_name': employee['users']['full_name'],
                'email': employee['users']['email'],
                'job_title_current': employee['position'],
                'department': employee['department'],
                'career_aspirations_next_role': employee['career_goal'] or f"Senior {employee['position']}",
                'tools_software_used_regularly': employee['key_tools'] or [],
                'company_id': employee['company_id'],
                'position': employee['position']
            }
            
        except Exception as e:
            logger.error(f"Failed to retrieve employee data: {e}")
            raise
    
    async def _retrieve_skills_gaps(self, employee_id: str, position: str) -> List[Dict[str, Any]]:
        """Retrieve skills gap analysis from database."""
        try:
            # Get skills profile with gap analysis
            response = self.supabase.table('st_employee_skills_profile').select(
                '*'
            ).eq('employee_id', employee_id).single().execute()
            
            if not response.data or not response.data.get('gap_analysis_completed_at'):
                raise Exception("Skills gap analysis not found or not completed")
            
            profile = response.data
            skills_gaps = []
            
            # Extract technical skills gaps - handle array format from database
            if profile.get('technical_skills') and isinstance(profile['technical_skills'], list):
                for skill_data in profile['technical_skills']:
                    # For skills analysis, assume all skills have some improvement potential
                    skill_name = skill_data.get('skill_name', 'Unknown Skill')
                    current_level = skill_data.get('proficiency_level', 3)
                    required_level = 5  # Assume target level is expert
                    
                    # Calculate gap severity based on proficiency difference
                    if current_level < required_level:
                        gap_severity = 'critical' if current_level < 2 else 'moderate' if current_level < 4 else 'minor'
                        skills_gaps.append({
                            'skill_name': skill_name,
                            'gap_severity': gap_severity,
                            'current_level': current_level,
                            'required_level': required_level,
                            'skill_type': 'technical'
                        })
            
            # Extract soft skills gaps - handle array format from database
            if profile.get('soft_skills') and isinstance(profile['soft_skills'], list):
                for skill_data in profile['soft_skills']:
                    # For skills analysis, assume all skills have some improvement potential
                    skill_name = skill_data.get('skill_name', 'Unknown Skill')
                    current_level = skill_data.get('proficiency_level', 3)
                    required_level = 5  # Assume target level is expert
                    
                    # Calculate gap severity based on proficiency difference
                    if current_level < required_level:
                        gap_severity = 'critical' if current_level < 2 else 'moderate' if current_level < 4 else 'minor'
                        skills_gaps.append({
                            'skill_name': skill_name,
                            'gap_severity': gap_severity,
                            'current_level': current_level,
                            'required_level': required_level,
                            'skill_type': 'soft'
                        })
            
            # Sort by severity
            severity_order = {'critical': 0, 'major': 1, 'moderate': 2, 'minor': 3}
            skills_gaps.sort(key=lambda x: severity_order.get(x['gap_severity'], 4))
            
            logger.info(f"ðŸ“Š Retrieved {len(skills_gaps)} skills gaps for employee")
            return skills_gaps
            
        except Exception as e:
            logger.error(f"Failed to retrieve skills gaps: {e}")
            raise
    
    
    async def _create_course_assignment(
        self,
        employee_id: str,
        content_id: str,
        company_id: str,
        assigned_by_id: str
    ) -> str:
        """Create course assignment in database."""
        try:
            from datetime import timedelta
            due_date = datetime.now() + timedelta(days=30)
            
            response = self.supabase.table('course_assignments').insert({
                'employee_id': employee_id,
                'course_id': content_id,
                'company_id': company_id,
                'assigned_by': assigned_by_id,
                'assigned_at': datetime.now().isoformat(),
                'due_date': due_date.isoformat(),
                'priority': 'high',
                'status': 'assigned',
                'progress_percentage': 0
            }).execute()
            
            assignment_id = response.data[0]['id'] if response.data else str(uuid.uuid4())
            logger.info(f"âœ… Created course assignment: {assignment_id}")
            return assignment_id
            
        except Exception as e:
            logger.error(f"Failed to create course assignment: {e}")
            raise
    
    async def _update_job_progress(self, job_id: str, updates: Dict[str, Any]):
        """Update course generation job progress."""
        try:
            self.supabase.table('course_generation_jobs').update({
                **updates,
                'updated_at': datetime.now().isoformat()
            }).eq('id', job_id).execute()
        except Exception as e:
            logger.error(f"Failed to update job progress: {e}")


# Convenience function for edge function integration
async def generate_course_with_agents(
    employee_id: str,
    company_id: str,
    assigned_by_id: str,
    job_id: Optional[str] = None
) -> Dict[str, Any]:
    """
    Generate a course using the full agent pipeline with database integration.
    
    This is the main entry point for the edge function to call.
    """
    pipeline = LXERADatabasePipeline()
    return await pipeline.generate_course_for_employee(
        employee_id,
        company_id,
        assigned_by_id,
        job_id
    )


if __name__ == "__main__":
    """Test the LXERA database pipeline."""
    
    async def test_pipeline():
        # Test with sample employee ID
        result = await generate_course_with_agents(
            employee_id="test-employee-id",
            company_id="test-company-id",
            assigned_by_id="test-user-id"
        )
        print(json.dumps(result, indent=2))
    
    asyncio.run(test_pipeline())