# üöÄ Comprehensive Agent Pipeline Upgrade Plan

## Executive Summary
This plan addresses all identified gaps to create a production-ready, fully integrated agent pipeline with proper handoffs, database storage, and error recovery.

## üìã Phase 1: Database Schema Completion (Priority: Critical)

### 1.1 Create Missing Tables
```sql
-- File: migrations/add_missing_tables.sql

-- Course Plans table (stores Planning Agent output)
CREATE TABLE IF NOT EXISTS cm_course_plans (
    plan_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    employee_id UUID NOT NULL REFERENCES employees(id),
    employee_name TEXT NOT NULL,
    session_id TEXT NOT NULL,
    
    -- Planning outputs
    course_structure JSONB NOT NULL,
    prioritized_gaps JSONB NOT NULL,
    research_strategy JSONB,
    learning_path JSONB,
    
    -- Metadata
    employee_profile JSONB,
    planning_agent_version TEXT DEFAULT 'v1',
    total_modules INTEGER,
    course_duration_weeks INTEGER,
    course_title TEXT,
    
    -- Tracking
    tool_calls JSONB[],
    execution_time_seconds DECIMAL,
    agent_turns INTEGER,
    
    status TEXT DEFAULT 'completed',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Agent Handoffs tracking
CREATE TABLE IF NOT EXISTS cm_agent_handoffs (
    handoff_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    session_id TEXT NOT NULL,
    from_agent TEXT NOT NULL,
    to_agent TEXT NOT NULL,
    handoff_context JSONB,
    content_id UUID REFERENCES cm_module_content(content_id),
    plan_id UUID REFERENCES cm_course_plans(plan_id),
    handoff_timestamp TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    success BOOLEAN DEFAULT true,
    error_details TEXT
);

-- Course Generation Jobs (referenced but missing)
CREATE TABLE IF NOT EXISTS course_generation_jobs (
    job_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    company_id UUID NOT NULL,
    initiated_by UUID NOT NULL,
    
    -- Job details
    total_employees INTEGER NOT NULL,
    successful_courses INTEGER DEFAULT 0,
    failed_courses INTEGER DEFAULT 0,
    
    -- Progress tracking
    status TEXT DEFAULT 'pending',
    current_phase TEXT,
    progress_percentage INTEGER DEFAULT 0,
    current_employee_id UUID,
    current_employee_name TEXT,
    
    -- Timing
    started_at TIMESTAMP WITH TIME ZONE,
    completed_at TIMESTAMP WITH TIME ZONE,
    estimated_completion TIMESTAMP WITH TIME ZONE,
    
    -- Error tracking
    error_message TEXT,
    failed_employee_ids UUID[],
    
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Add indexes
CREATE INDEX idx_cm_course_plans_employee ON cm_course_plans(employee_id);
CREATE INDEX idx_cm_course_plans_session ON cm_course_plans(session_id);
CREATE INDEX idx_cm_agent_handoffs_session ON cm_agent_handoffs(session_id);
CREATE INDEX idx_course_generation_jobs_company ON course_generation_jobs(company_id);
CREATE INDEX idx_course_generation_jobs_status ON course_generation_jobs(status);
```

## üìã Phase 2: Agent Architecture Fixes

### 2.1 Planning Agent Updates
- Add database storage tools
- Add handoff to Research Agent
- Keep all existing analysis tools

### 2.2 Research Agent Updates  
- Add database storage tools
- Add handoff to Content Agent
- Keep all existing research tools

### 2.3 Create Unified Coordinator
- Start with Planning Agent
- Monitor pipeline flow
- Handle error recovery

## üìã Phase 3: Pipeline Integration

### 3.1 Update Main Orchestrator
- Use coordinator instead of individual agents
- Single entry point for pipeline
- Proper handoff tracking

### 3.2 Add Progress Tracking
- Track agent handoffs in database
- Update job progress
- Monitor execution time

## üìã Phase 4: Testing & Validation

### 4.1 Component Tests
- Test each agent individually
- Verify tool execution
- Check database operations

### 4.2 Integration Tests
- Full pipeline execution
- Verify handoffs
- Check data persistence

### 4.3 Performance Tests
- Token usage verification
- Execution time benchmarks
- Memory usage monitoring

## üìã Phase 5: Deployment Steps

### 5.1 Database Migration
```bash
# Run migration
supabase migration new add_agent_pipeline_tables
# Add SQL from Phase 1
supabase db push
```

### 5.2 Backend Deployment
```bash
# Test locally
python testing/test_full_pipeline.py

# Deploy to Render
git add .
git commit -m "feat: unified agent pipeline with proper handoffs"
git push origin main
```

### 5.3 Monitoring
- OpenAI Traces dashboard
- Database query monitoring
- Sentry error tracking
- Performance metrics

## üéØ Success Criteria

1. **Agent Handoffs**: All agents properly hand off through SDK
2. **Database Storage**: All results stored (plans, research, content)
3. **Error Recovery**: Can resume from any failure point
4. **Performance**: 98% token reduction maintained
5. **Monitoring**: Full visibility in OpenAI Traces
6. **User Experience**: Seamless course generation

## üöÄ Expected Outcome

After implementation:
1. Click "Generate Course" ‚Üí Creates job
2. Coordinator ‚Üí Planning (stores plan) ‚Üí Research (stores findings) ‚Üí Content (stores sections) ‚Üí Quality ‚Üí Enhancement ‚Üí Multimedia ‚Üí Finalizer
3. Each handoff tracked in database
4. Full course ready in ~3-5 minutes
5. User redirected to course viewer
6. Complete audit trail in databases

## ‚è∞ Timeline

- Phase 1: 2 hours (Database setup)
- Phase 2: 3 hours (Agent updates)
- Phase 3: 2 hours (Pipeline integration)
- Phase 4: 3 hours (Testing)
- Phase 5: 2 hours (Deployment)

**Total: ~12 hours** for complete implementation