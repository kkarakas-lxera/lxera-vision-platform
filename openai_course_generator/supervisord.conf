[unix_http_server]
file=/tmp/supervisor.sock

[supervisord]
logfile=/var/log/supervisord.log
logfile_maxbytes=50MB
logfile_backups=10
loglevel=info
pidfile=/tmp/supervisord.pid
nodaemon=false
minfds=1024
minprocs=200

[rpcinterface:supervisor]
supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface

[supervisorctl]
serverurl=unix:///tmp/supervisor.sock

[program:course_worker]
command=python3 /workspace/openai_course_generator/vast_worker.py
directory=/workspace/openai_course_generator
user=root
autostart=true
autorestart=true
redirect_stderr=true
stdout_logfile=/var/log/course_worker.log
stdout_logfile_maxbytes=10MB
stdout_logfile_backups=5
stderr_logfile=/var/log/course_worker_error.log
stderr_logfile_maxbytes=10MB
stderr_logfile_backups=5
environment=PYTHONPATH="/workspace:/workspace/openai_course_generator",
    PYTHONUNBUFFERED="1",
    MAX_CONCURRENT_JOBS="2",
    POLL_INTERVAL_SECONDS="5"

[program:api_server]
command=gunicorn --bind 127.0.0.1:8081 --workers 2 --timeout 300 --log-level info api_server:app
directory=/workspace/openai_course_generator
user=root
autostart=true
autorestart=true
redirect_stderr=true
stdout_logfile=/var/log/api_server.log
stdout_logfile_maxbytes=10MB
stdout_logfile_backups=5
stderr_logfile=/var/log/api_server_error.log
stderr_logfile_maxbytes=10MB
stderr_logfile_backups=5
environment=PYTHONPATH="/workspace:/workspace/openai_course_generator",
    PYTHONUNBUFFERED="1",
    PORT="8081"

[program:ollama_serve]
command=ollama serve
user=root
autostart=true
autorestart=true
redirect_stderr=true
stdout_logfile=/var/log/ollama.log
stdout_logfile_maxbytes=10MB
stdout_logfile_backups=3
stderr_logfile=/var/log/ollama_error.log
stderr_logfile_maxbytes=10MB
stderr_logfile_backups=3
environment=OLLAMA_HOST="127.0.0.1:11434",
    OLLAMA_ORIGINS="*"